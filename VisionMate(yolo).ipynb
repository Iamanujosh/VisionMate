{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515f545c",
   "metadata": {},
   "source": [
    "# 1.Install and import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f5031",
   "metadata": {},
   "source": [
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941bcebd",
   "metadata": {},
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5b1c8",
   "metadata": {},
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc1e479",
   "metadata": {},
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ab9d2a",
   "metadata": {},
   "source": [
    "!cd yolov5 & pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5ff101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyttsx3\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466c8496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0a7a6",
   "metadata": {},
   "source": [
    "# 2.Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9277c",
   "metadata": {},
   "source": [
    "Loading yolov5s->s for small model from pytorch with following syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "750c6f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Anushka/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-1-26 Python-3.11.5 torch-2.1.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model=torch.hub.load('ultralytics/yolov5','yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6f96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "903acb60",
   "metadata": {},
   "source": [
    "# 4.Real time detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dda3469",
   "metadata": {},
   "source": [
    "!pip install SpeechRecognitionimport speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6977c14",
   "metadata": {},
   "source": [
    "!pip install PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44e10907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something:\n",
      "You said: start\n",
      "Camera started.\n",
      "Command: stop\n",
      "Stopping camera.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pyttsx3\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import sys\n",
    "\n",
    "def record_audio():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        #engine = pyttsx3.init()\n",
    "       # sengine.say\n",
    "        print(\"Say something:\")\n",
    "        audio = recognizer.listen(source)\n",
    "    return audio\n",
    "\n",
    "class CameraController:\n",
    "    def __init__(self):\n",
    "        self.cap = None\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.engine = pyttsx3.init()\n",
    "\n",
    "    def start_camera(self):\n",
    "        if self.cap is None:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            print(\"Camera started.\")\n",
    "            self.engine.say(\"Camera started.\")\n",
    "            self.engine.runAndWait()\n",
    "            \n",
    "            while self.cap.isOpened():\n",
    "                \n",
    "                ret, frame = self.cap.read() \n",
    "                # Make detections \n",
    "                results = model(frame)\n",
    "                cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "                names = [model.names[int(obj[5])] for obj in results.xyxy[0]]\n",
    "                # Convert detected object names to a text string\n",
    "                #text_to_speak = ', '.join(names)\n",
    "                # Speak the text\n",
    "                self.engine.say(names)\n",
    "                self.engine.runAndWait()\n",
    "                command = self.listen_voice_command()\n",
    "                if command and \"stop\" in command.lower():\n",
    "                    print(\"Stopping camera.\")\n",
    "                    self.engine.say(\"Stopping camera.\")\n",
    "                    self.engine.runAndWait()\n",
    "                    self.cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    self.cap = None\n",
    "                    sys.exit()\n",
    "\n",
    "        else:\n",
    "            print(\"Camera is already running.\")\n",
    "            self.engine.say(\"Camera is already running.\")\n",
    "            self.engine.runAndWait()\n",
    "    \n",
    "    def listen_voice_command(self):\n",
    "        with sr.Microphone() as source:\n",
    "            #self.engine.say(\"Say a command:\")\n",
    "            #self.engine.runAndWait()\n",
    "            audio = self.recognizer.listen(source)\n",
    "\n",
    "            try:\n",
    "                command = self.recognizer.recognize_google(audio)\n",
    "                print(\"Command:\", command)\n",
    "                return command\n",
    "            except sr.UnknownValueError:\n",
    "                return None\n",
    "\n",
    "    def stop_camera(self):\n",
    "        if self.cap is not None:\n",
    "            self.cap.release()\n",
    "            self.cap = None\n",
    "            print(\"Camera stopped.\")\n",
    "            self.engine.say(\"Camera stopped.\")\n",
    "            self.engine.runAndWait()\n",
    "        else:\n",
    "            print(\"Camera is not running.\")\n",
    "            self.engine.say(\"Camera is not running.\")\n",
    "            self.engine.runAndWait()\n",
    "\n",
    "    def recognize_speech(self, audio):\n",
    "        try:\n",
    "            while True:\n",
    "                \n",
    "                text = self.recognizer.recognize_google(audio)\n",
    "                print(\"You said:\", text)\n",
    "                self.engine.say(text)\n",
    "                self.engine.runAndWait()\n",
    "\n",
    "                if \"start\" in text.lower():\n",
    "                    self.start_camera()\n",
    "                if \"stop\" in text.lower():\n",
    "                    self.stop_camera()\n",
    "                    break\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I couldn't understand that.\")\n",
    "            self.engine.say(\"Sorry, I couldn't understand that.\")\n",
    "            self.engine.runAndWait()\n",
    "        except sr.RequestError:\n",
    "            print(\"Could not request results from Google Speech Recognition service.\")\n",
    "            self.engine.say(\"Could not request results from Google Speech Recognition service.\")\n",
    "            self.engine.runAndWait()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio = record_audio()\n",
    "    cam = CameraController()\n",
    "    cam.recognize_speech(audio)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
